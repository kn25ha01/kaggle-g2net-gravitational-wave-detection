{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1632195065078,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"bkdrPIruLcOR","outputId":"34dd8de9-25c6-4484-cac0-3eeef3dcc399"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Sep 21 03:31:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"q_JW-l7Ygsdq"},"source":["## Common Setting"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40660,"status":"ok","timestamp":1632195113821,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"vrQiVLqHUZFH","outputId":"b644a923-322f-4256-c274-48e1595254d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","is_use_gcs = True\n","if is_use_gcs:\n","    from google.colab import auth\n","    auth.authenticate_user()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7837,"status":"ok","timestamp":1632195128979,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"iBNGuhVA5ssA","outputId":"077f6712-75aa-4262-95d1-1616b757ba77"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 42.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n","\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","/root/.kaggle was made.\n"]}],"source":["import os\n","import sys\n","\n","COMPETITION_NAME = 'g2net-gravitational-wave-detection'\n","\n","KAGGLE_DIR = '/content/gdrive/MyDrive/kaggle'\n","sys.path.append(KAGGLE_DIR)\n","from scripts.utils import mkdir, load_json\n","\n","# prepare wandb\n","WANDB_JSON_PATH = f\"{KAGGLE_DIR}/secrets/wandb.json\"\n","\n","# prepare kaggle API\n","!pip install -q kaggle\n","!pip install -q --upgrade --force-reinstall --no-deps kaggle\n","mkdir('/root/.kaggle')\n","!cp {KAGGLE_DIR}/secrets/kaggle.json /root/.kaggle/\n"]},{"cell_type":"markdown","metadata":{"id":"v9jQW7bThDga"},"source":["## Prepare Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14707,"status":"ok","timestamp":1632195146232,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"a7aYYq4zVYpY","outputId":"4737b05f-2426-47e2-be81-4f00d823da4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/input was made.\n","deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2537  100  2537    0     0  93962      0 --:--:-- --:--:-- --:--:-- 93962\n","OK\n","Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.4 kB]\n","Get:15 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,385 B]\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,761 kB]\n","Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,326 kB]\n","Get:23 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [454 B]\n","Get:24 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n","Fetched 11.8 MB in 3s (4,209 kB/s)\n","Reading package lists...\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","The following NEW packages will be installed:\n","  gcsfuse\n","0 upgraded, 1 newly installed, 0 to remove and 56 not upgraded.\n","Need to get 10.8 MB of archives.\n","After this operation, 23.2 MB of additional disk space will be used.\n","Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.36.0 [10.8 MB]\n","Fetched 10.8 MB in 0s (29.6 MB/s)\n","Selecting previously unselected package gcsfuse.\n","(Reading database ... 155013 files and directories currently installed.)\n","Preparing to unpack .../gcsfuse_0.36.0_amd64.deb ...\n","Unpacking gcsfuse (0.36.0) ...\n","Setting up gcsfuse (0.36.0) ...\n","/content/input/train_fold01 was made.\n","2021/09/21 03:32:24.241230 Using mount point: /content/input/train_fold01\n","2021/09/21 03:32:24.248021 Opening GCS connection...\n","2021/09/21 03:32:24.592162 Mounting file system \"kds-51f153f632521a32be4425a82f5ef3b9d1330dc5cab7403a059157f5\"...\n","2021/09/21 03:32:24.593471 File system has been successfully mounted.\n","/content/input/train_fold23 was made.\n","2021/09/21 03:32:24.649579 Using mount point: /content/input/train_fold23\n","2021/09/21 03:32:24.656093 Opening GCS connection...\n","2021/09/21 03:32:24.978977 Mounting file system \"kds-be6b664556db70d53096072ab31ed1183329271fd0df17be418c1cc5\"...\n","2021/09/21 03:32:24.980146 File system has been successfully mounted.\n","/content/input/test was made.\n","2021/09/21 03:32:25.060412 Using mount point: /content/input/test\n","2021/09/21 03:32:25.066463 Opening GCS connection...\n","2021/09/21 03:32:25.460397 Mounting file system \"kds-9e101f96a723d803be9e0b1537cbf82c6a27ded057f1df58b1738853\"...\n","2021/09/21 03:32:25.461516 File system has been successfully mounted.\n"]}],"source":["# prepare input dir\n","GDRIVE_INPUT_DIR = f'{KAGGLE_DIR}/competitions/{COMPETITION_NAME}/input'\n","COLAB_INPUT_DIR = '/content/input'\n","mkdir(COLAB_INPUT_DIR)\n","\n","# copy into colab\n","is_copy = True\n","if is_copy:\n","    %cp -r {GDRIVE_INPUT_DIR}/* {COLAB_INPUT_DIR}/\n","\n","# mount gcs to access kaggle personal dataset\n","if is_use_gcs:\n","    # install gcsfuse\n","    !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n","    !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","    !apt-get -y -q update\n","    !apt-get -y -q install gcsfuse\n","\n","    # mount\n","    bucket_ids = load_json(f\"{GDRIVE_INPUT_DIR}/gcs.json\")\n","    for k, v in bucket_ids.items():\n","        mount_dir = os.path.join(COLAB_INPUT_DIR, k)\n","        mkdir(mount_dir)\n","        !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {v} {mount_dir}\n"]},{"cell_type":"markdown","metadata":{"id":"QeJ5RAX4gjvJ"},"source":["## Prepare working directory"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7948,"status":"ok","timestamp":1632195155641,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"U3zDJ52_SN2S","outputId":"eea76558-4273-47c7-a9ec-513e47d359c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/kaggle/competitions/g2net-gravitational-wave-detection/working/006\n","core.repositoryformatversion=0\n","core.filemode=true\n","core.bare=false\n","core.logallrefupdates=true\n","remote.origin.url=https://kn25ha01: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@github.com/kn25ha01/kaggle-g2net-gravitational-wave-detection.git\n","remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n","branch.main.remote=origin\n","branch.main.merge=refs/heads/main\n","user.name=kn25ha01\n","user.email=kn25ha01@gmail.com\n","\n","No commits yet\n","\n","Changes to be committed:\n","  (use \"git rm --cached \u003cfile\u003e...\" to unstage)\n","\n","\t\u001b[32mnew file:   .gitignore\u001b[m\n","\t\u001b[32mnew file:   LICENSE\u001b[m\n","\t\u001b[32mnew file:   README.md\u001b[m\n","\t\u001b[32mnew file:   config.py\u001b[m\n","\t\u001b[32mnew file:   main.ipynb\u001b[m\n","\t\u001b[32mnew file:   make_submission.py\u001b[m\n","\t\u001b[32mnew file:   requirements.txt\u001b[m\n","\t\u001b[32mnew file:   src/dataset_factory.py\u001b[m\n","\t\u001b[32mnew file:   src/helper.py\u001b[m\n","\t\u001b[32mnew file:   src/model_factory.py\u001b[m\n","\t\u001b[32mnew file:   src/utils.py\u001b[m\n","\t\u001b[32mnew file:   train.py\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add \u003cfile\u003e...\" to update what will be committed)\n","  (use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   main.ipynb\u001b[m\n","\n"]}],"source":["# prepare work dir\n","from scripts.utils import get_work_dir\n","WORKING_DIR = f'{KAGGLE_DIR}/competitions/{COMPETITION_NAME}/working'\n","WORK_DIR = get_work_dir(WORKING_DIR)\n","exp_num = os.path.basename(WORK_DIR)\n","%cd {WORK_DIR}\n","!git config -l\n","!git status\n"]},{"cell_type":"markdown","metadata":{"id":"7icoeVHTXY2I"},"source":["## Install Packages"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7809,"status":"ok","timestamp":1632195182701,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"aGGD8bYFfZ9T","outputId":"56725c53-613d-4cb9-d912-390cc7072c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.7 MB 13.4 MB/s \n","\u001b[K     |████████████████████████████████| 376 kB 67.1 MB/s \n","\u001b[K     |████████████████████████████████| 97 kB 8.1 MB/s \n","\u001b[K     |████████████████████████████████| 180 kB 74.8 MB/s \n","\u001b[K     |████████████████████████████████| 133 kB 76.3 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"XBl8nVwDMIUT"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uykM-8ZjXzov"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W\u0026B API key is configured (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaoyakintoki\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m006_fold0\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/naoyakintoki/kaggle-g2net-gravitational-wave-detection\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/naoyakintoki/kaggle-g2net-gravitational-wave-detection/runs/3c8qpmu5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/006/wandb/run-20210921_080157-3c8qpmu5\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n","\n","========== fold: 0 training ==========\n","/usr/local/lib/python3.7/dist-packages/nnAudio/utils.py:326: SyntaxWarning: If fmax is given, n_bins will be ignored\n","  warnings.warn('If fmax is given, n_bins will be ignored',SyntaxWarning)\n","CQT kernels created, time used = 0.0441 seconds\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ns-1dbc32de.pth\n","2021-09-21 08:02:14.995328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:15.688978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:15.689794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:15.691106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-09-21 08:02:15.691621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:15.692236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:15.692834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:18.342201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:18.342852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:18.343464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-21 08:02:18.344086: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-21 08:02:18.344137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13374 MB memory:  -\u003e device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2021-09-21 08:02:18.637046: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch: [1/5][0/6563] Loss: 0.7108(0.7108) Grad: 2.9402  LR: 0.000100  Elapsed: 0m 6s (remain 656m 18s) Max mem: 9018 MB\n","Epoch: [1/5][100/6563] Loss: 0.5588(0.6261) Grad: 1.8509  LR: 0.000100  Elapsed: 0m 37s (remain 39m 57s) Max mem: 9779 MB\n","Epoch: [1/5][200/6563] Loss: 0.4544(0.5891) Grad: 1.2190  LR: 0.000100  Elapsed: 1m 9s (remain 36m 25s) Max mem: 9779 MB\n","Epoch: [1/5][300/6563] Loss: 0.7066(0.5631) Grad: 3.5098  LR: 0.000100  Elapsed: 1m 40s (remain 34m 47s) Max mem: 9779 MB\n","Epoch: [1/5][400/6563] Loss: 0.4481(0.5489) Grad: 0.8669  LR: 0.000100  Elapsed: 2m 11s (remain 33m 44s) Max mem: 9779 MB\n","Epoch: [1/5][500/6563] Loss: 0.4014(0.5359) Grad: 0.9655  LR: 0.000100  Elapsed: 2m 43s (remain 32m 53s) Max mem: 9779 MB\n","Epoch: [1/5][600/6563] Loss: 0.6097(0.5267) Grad: 1.7724  LR: 0.000100  Elapsed: 3m 14s (remain 32m 12s) Max mem: 9779 MB\n","Epoch: [1/5][700/6563] Loss: 0.4321(0.5199) Grad: 1.1011  LR: 0.000100  Elapsed: 3m 46s (remain 31m 31s) Max mem: 9779 MB\n","Epoch: [1/5][800/6563] Loss: 0.4401(0.5147) Grad: 0.7739  LR: 0.000100  Elapsed: 4m 17s (remain 30m 53s) Max mem: 9779 MB\n","Epoch: [1/5][900/6563] Loss: 0.5579(0.5101) Grad: 1.2056  LR: 0.000100  Elapsed: 4m 49s (remain 30m 16s) Max mem: 9779 MB\n","Epoch: [1/5][1000/6563] Loss: 0.5238(0.5059) Grad: 0.8744  LR: 0.000100  Elapsed: 5m 20s (remain 29m 41s) Max mem: 9779 MB\n","Epoch: [1/5][1100/6563] Loss: 0.4231(0.5030) Grad: 0.7087  LR: 0.000100  Elapsed: 5m 52s (remain 29m 6s) Max mem: 9779 MB\n","Epoch: [1/5][1200/6563] Loss: 0.4254(0.4995) Grad: 0.8811  LR: 0.000100  Elapsed: 6m 23s (remain 28m 31s) Max mem: 9779 MB\n","Epoch: [1/5][1300/6563] Loss: 0.5074(0.4971) Grad: 0.8684  LR: 0.000100  Elapsed: 6m 54s (remain 27m 58s) Max mem: 9779 MB\n","Epoch: [1/5][1400/6563] Loss: 0.4774(0.4948) Grad: 0.9236  LR: 0.000100  Elapsed: 7m 26s (remain 27m 25s) Max mem: 9779 MB\n","Epoch: [1/5][1500/6563] Loss: 0.5787(0.4933) Grad: 1.8497  LR: 0.000100  Elapsed: 7m 57s (remain 26m 51s) Max mem: 9779 MB\n","Epoch: [1/5][1600/6563] Loss: 0.4263(0.4901) Grad: 0.6238  LR: 0.000100  Elapsed: 8m 29s (remain 26m 19s) Max mem: 9779 MB\n","Epoch: [1/5][1700/6563] Loss: 0.5583(0.4887) Grad: 1.1734  LR: 0.000100  Elapsed: 9m 1s (remain 25m 46s) Max mem: 9779 MB\n","Epoch: [1/5][1800/6563] Loss: 0.4054(0.4870) Grad: 0.7288  LR: 0.000100  Elapsed: 9m 32s (remain 25m 14s) Max mem: 9779 MB\n","Epoch: [1/5][1900/6563] Loss: 0.4286(0.4855) Grad: 0.7230  LR: 0.000100  Elapsed: 10m 3s (remain 24m 41s) Max mem: 9779 MB\n","Epoch: [1/5][2000/6563] Loss: 0.4514(0.4843) Grad: 0.6967  LR: 0.000100  Elapsed: 10m 35s (remain 24m 9s) Max mem: 9779 MB\n","Epoch: [1/5][2100/6563] Loss: 0.4070(0.4833) Grad: 1.0438  LR: 0.000100  Elapsed: 11m 7s (remain 23m 37s) Max mem: 9779 MB\n","Epoch: [1/5][2200/6563] Loss: 0.4210(0.4822) Grad: 0.9555  LR: 0.000100  Elapsed: 11m 38s (remain 23m 4s) Max mem: 9779 MB\n","Epoch: [1/5][2300/6563] Loss: 0.4669(0.4810) Grad: 0.7570  LR: 0.000100  Elapsed: 12m 10s (remain 22m 32s) Max mem: 9779 MB\n","Epoch: [1/5][2400/6563] Loss: 0.4303(0.4797) Grad: 0.4546  LR: 0.000100  Elapsed: 12m 41s (remain 22m 0s) Max mem: 9779 MB\n","Epoch: [1/5][2500/6563] Loss: 0.3230(0.4787) Grad: 1.0860  LR: 0.000100  Elapsed: 13m 13s (remain 21m 28s) Max mem: 9779 MB\n","Epoch: [1/5][2600/6563] Loss: 0.5450(0.4784) Grad: 1.3674  LR: 0.000100  Elapsed: 13m 44s (remain 20m 56s) Max mem: 9779 MB\n","Epoch: [1/5][2700/6563] Loss: 0.3552(0.4769) Grad: 0.7281  LR: 0.000100  Elapsed: 14m 16s (remain 20m 24s) Max mem: 9779 MB\n","Epoch: [1/5][2800/6563] Loss: 0.4081(0.4763) Grad: 1.3942  LR: 0.000100  Elapsed: 14m 48s (remain 19m 52s) Max mem: 9779 MB\n","Epoch: [1/5][2900/6563] Loss: 0.4043(0.4758) Grad: 0.8042  LR: 0.000100  Elapsed: 15m 19s (remain 19m 21s) Max mem: 9779 MB\n","Epoch: [1/5][3000/6563] Loss: 0.3659(0.4750) Grad: 1.4877  LR: 0.000100  Elapsed: 15m 51s (remain 18m 49s) Max mem: 9779 MB\n","Epoch: [1/5][3100/6563] Loss: 0.4637(0.4742) Grad: 0.7854  LR: 0.000100  Elapsed: 16m 22s (remain 18m 17s) Max mem: 9779 MB\n","Epoch: [1/5][3200/6563] Loss: 0.4398(0.4733) Grad: 1.1095  LR: 0.000100  Elapsed: 16m 54s (remain 17m 45s) Max mem: 9779 MB\n","Epoch: [1/5][3300/6563] Loss: 0.5167(0.4727) Grad: 0.6735  LR: 0.000100  Elapsed: 17m 25s (remain 17m 13s) Max mem: 9779 MB\n","Epoch: [1/5][3400/6563] Loss: 0.4826(0.4716) Grad: 1.1683  LR: 0.000100  Elapsed: 17m 57s (remain 16m 41s) Max mem: 9779 MB\n","Epoch: [1/5][3500/6563] Loss: 0.5062(0.4710) Grad: 0.9572  LR: 0.000100  Elapsed: 18m 28s (remain 16m 9s) Max mem: 9779 MB\n","Epoch: [1/5][3600/6563] Loss: 0.4090(0.4702) Grad: 0.6990  LR: 0.000100  Elapsed: 19m 0s (remain 15m 37s) Max mem: 9779 MB\n","Epoch: [1/5][3700/6563] Loss: 0.4709(0.4697) Grad: 0.7765  LR: 0.000100  Elapsed: 19m 31s (remain 15m 6s) Max mem: 9779 MB\n","Epoch: [1/5][3800/6563] Loss: 0.3921(0.4688) Grad: 0.7927  LR: 0.000100  Elapsed: 20m 3s (remain 14m 34s) Max mem: 9779 MB\n","Epoch: [1/5][3900/6563] Loss: 0.4231(0.4683) Grad: 0.6920  LR: 0.000100  Elapsed: 20m 34s (remain 14m 2s) Max mem: 9779 MB\n","Epoch: [1/5][4000/6563] Loss: 0.4051(0.4677) Grad: 0.7781  LR: 0.000100  Elapsed: 21m 6s (remain 13m 30s) Max mem: 9779 MB\n","Epoch: [1/5][4100/6563] Loss: 0.3431(0.4669) Grad: 0.6944  LR: 0.000100  Elapsed: 21m 37s (remain 12m 59s) Max mem: 9779 MB\n","Epoch: [1/5][4200/6563] Loss: 0.3968(0.4663) Grad: 0.7637  LR: 0.000100  Elapsed: 22m 9s (remain 12m 27s) Max mem: 9779 MB\n","Epoch: [1/5][4300/6563] Loss: 0.5164(0.4656) Grad: 0.8523  LR: 0.000100  Elapsed: 22m 40s (remain 11m 55s) Max mem: 9779 MB\n","Epoch: [1/5][4400/6563] Loss: 0.3738(0.4651) Grad: 0.7234  LR: 0.000100  Elapsed: 23m 12s (remain 11m 23s) Max mem: 9779 MB\n","Epoch: [1/5][4500/6563] Loss: 0.4539(0.4647) Grad: 0.9102  LR: 0.000100  Elapsed: 23m 43s (remain 10m 52s) Max mem: 9779 MB\n","Epoch: [1/5][4600/6563] Loss: 0.4803(0.4643) Grad: 1.2978  LR: 0.000100  Elapsed: 24m 15s (remain 10m 20s) Max mem: 9779 MB\n","Epoch: [1/5][4700/6563] Loss: 0.2896(0.4638) Grad: 0.9877  LR: 0.000100  Elapsed: 24m 46s (remain 9m 48s) Max mem: 9779 MB\n","Epoch: [1/5][4800/6563] Loss: 0.3813(0.4637) Grad: 0.7977  LR: 0.000100  Elapsed: 25m 18s (remain 9m 17s) Max mem: 9779 MB\n","Epoch: [1/5][4900/6563] Loss: 0.4937(0.4632) Grad: 1.3900  LR: 0.000100  Elapsed: 25m 50s (remain 8m 45s) Max mem: 9779 MB\n","Epoch: [1/5][5000/6563] Loss: 0.4156(0.4626) Grad: 1.0350  LR: 0.000100  Elapsed: 26m 21s (remain 8m 14s) Max mem: 9779 MB\n","Epoch: [1/5][5100/6563] Loss: 0.5514(0.4621) Grad: 1.3735  LR: 0.000100  Elapsed: 26m 53s (remain 7m 42s) Max mem: 9779 MB\n","Epoch: [1/5][5200/6563] Loss: 0.4654(0.4617) Grad: 0.8818  LR: 0.000100  Elapsed: 27m 25s (remain 7m 10s) Max mem: 9779 MB\n","Epoch: [1/5][5300/6563] Loss: 0.4218(0.4612) Grad: 0.7144  LR: 0.000100  Elapsed: 27m 56s (remain 6m 39s) Max mem: 9779 MB\n","Epoch: [1/5][5400/6563] Loss: 0.5879(0.4608) Grad: 1.3602  LR: 0.000100  Elapsed: 28m 27s (remain 6m 7s) Max mem: 9779 MB\n","Epoch: [1/5][5500/6563] Loss: 0.4760(0.4604) Grad: 0.7056  LR: 0.000100  Elapsed: 28m 59s (remain 5m 35s) Max mem: 9779 MB\n","Epoch: [1/5][5600/6563] Loss: 0.4851(0.4601) Grad: 1.2086  LR: 0.000100  Elapsed: 29m 30s (remain 5m 4s) Max mem: 9779 MB\n","Epoch: [1/5][5700/6563] Loss: 0.3832(0.4596) Grad: 0.9432  LR: 0.000100  Elapsed: 30m 2s (remain 4m 32s) Max mem: 9779 MB\n","Epoch: [1/5][5800/6563] Loss: 0.4356(0.4595) Grad: 0.8653  LR: 0.000100  Elapsed: 30m 34s (remain 4m 0s) Max mem: 9779 MB\n","Epoch: [1/5][5900/6563] Loss: 0.4038(0.4593) Grad: 0.7226  LR: 0.000100  Elapsed: 31m 5s (remain 3m 29s) Max mem: 9779 MB\n","Epoch: [1/5][6000/6563] Loss: 0.4850(0.4590) Grad: 0.9337  LR: 0.000100  Elapsed: 31m 37s (remain 2m 57s) Max mem: 9779 MB\n","Epoch: [1/5][6100/6563] Loss: 0.5469(0.4586) Grad: 1.2566  LR: 0.000100  Elapsed: 32m 8s (remain 2m 26s) Max mem: 9779 MB\n","Epoch: [1/5][6200/6563] Loss: 0.4826(0.4583) Grad: 1.2656  LR: 0.000100  Elapsed: 32m 40s (remain 1m 54s) Max mem: 9779 MB\n","Epoch: [1/5][6300/6563] Loss: 0.3329(0.4580) Grad: 0.9278  LR: 0.000100  Elapsed: 33m 11s (remain 1m 22s) Max mem: 9779 MB\n","Epoch: [1/5][6400/6563] Loss: 0.4533(0.4576) Grad: 0.9503  LR: 0.000100  Elapsed: 33m 43s (remain 0m 51s) Max mem: 9779 MB\n","Epoch: [1/5][6500/6563] Loss: 0.3527(0.4572) Grad: 1.3735  LR: 0.000100  Elapsed: 34m 15s (remain 0m 19s) Max mem: 9779 MB\n","EVAL: [0/1094] Data 1.136 (1.136) Elapsed 0m 1s (remain 23m 35s) Loss: 0.4534(0.4534) \n","EVAL: [100/1094] Data 0.002 (0.020) Elapsed 0m 16s (remain 2m 41s) Loss: 0.5622(0.4539) \n","EVAL: [200/1094] Data 0.003 (0.011) Elapsed 0m 30s (remain 2m 17s) Loss: 0.3900(0.4588) \n","EVAL: [300/1094] Data 0.002 (0.009) Elapsed 0m 45s (remain 1m 59s) Loss: 0.3768(0.4578) \n","EVAL: [400/1094] Data 0.002 (0.007) Elapsed 0m 59s (remain 1m 43s) Loss: 0.3942(0.4563) \n","EVAL: [500/1094] Data 0.007 (0.006) Elapsed 1m 14s (remain 1m 28s) Loss: 0.4344(0.4569) \n","EVAL: [600/1094] Data 0.004 (0.006) Elapsed 1m 29s (remain 1m 13s) Loss: 0.4543(0.4564) \n","EVAL: [700/1094] Data 0.003 (0.007) Elapsed 1m 44s (remain 0m 58s) Loss: 0.4864(0.4554) \n","EVAL: [800/1094] Data 0.003 (0.009) Elapsed 2m 1s (remain 0m 44s) Loss: 0.4685(0.4554) \n","EVAL: [900/1094] Data 0.003 (0.008) Elapsed 2m 15s (remain 0m 29s) Loss: 0.4753(0.4555) \n","EVAL: [1000/1094] Data 0.003 (0.008) Elapsed 2m 30s (remain 0m 13s) Loss: 0.4840(0.4561) \n","Epoch 1 - avg_train_loss: 0.4572  avg_val_loss: 0.4552  time: 2243s\n","Epoch 1 - Score: 0.8547\n","Epoch 1 - Save Best Score: 0.8547 Model\n","Epoch 1 - Save Best Loss: 0.4552 Model\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch: [2/5][0/6563] Loss: 0.3992(0.3992) Grad: 0.6982  LR: 0.000056  Elapsed: 0m 1s (remain 164m 28s) Max mem: 9779 MB\n","Epoch: [2/5][100/6563] Loss: 0.4722(0.4381) Grad: 0.6705  LR: 0.000056  Elapsed: 0m 33s (remain 35m 18s) Max mem: 9779 MB\n","Epoch: [2/5][200/6563] Loss: 0.4596(0.4388) Grad: 0.8573  LR: 0.000056  Elapsed: 1m 4s (remain 34m 15s) Max mem: 9779 MB\n","Epoch: [2/5][300/6563] Loss: 0.4192(0.4344) Grad: 1.1936  LR: 0.000056  Elapsed: 1m 36s (remain 33m 23s) Max mem: 9779 MB\n","Epoch: [2/5][400/6563] Loss: 0.4931(0.4328) Grad: 1.2498  LR: 0.000056  Elapsed: 2m 7s (remain 32m 46s) Max mem: 9779 MB\n","Epoch: [2/5][500/6563] Loss: 0.4207(0.4338) Grad: 0.7928  LR: 0.000056  Elapsed: 2m 39s (remain 32m 7s) Max mem: 9779 MB\n","Epoch: [2/5][600/6563] Loss: 0.4806(0.4336) Grad: 1.0206  LR: 0.000056  Elapsed: 3m 10s (remain 31m 33s) Max mem: 9779 MB\n","Epoch: [2/5][700/6563] Loss: 0.4357(0.4339) Grad: 0.8563  LR: 0.000056  Elapsed: 3m 42s (remain 31m 0s) Max mem: 9779 MB\n","Epoch: [2/5][800/6563] Loss: 0.4153(0.4335) Grad: 0.9587  LR: 0.000056  Elapsed: 4m 13s (remain 30m 26s) Max mem: 9779 MB\n","Epoch: [2/5][900/6563] Loss: 0.3815(0.4340) Grad: 0.7150  LR: 0.000056  Elapsed: 4m 45s (remain 29m 53s) Max mem: 9779 MB\n","Epoch: [2/5][1000/6563] Loss: 0.5386(0.4339) Grad: 0.9928  LR: 0.000056  Elapsed: 5m 16s (remain 29m 19s) Max mem: 9779 MB\n","Epoch: [2/5][1100/6563] Loss: 0.4164(0.4337) Grad: 0.9781  LR: 0.000056  Elapsed: 5m 48s (remain 28m 46s) Max mem: 9779 MB\n","Epoch: [2/5][1200/6563] Loss: 0.4504(0.4342) Grad: 0.6541  LR: 0.000056  Elapsed: 6m 19s (remain 28m 13s) Max mem: 9779 MB\n","Epoch: [2/5][1300/6563] Loss: 0.3968(0.4342) Grad: 0.8464  LR: 0.000056  Elapsed: 6m 50s (remain 27m 42s) Max mem: 9779 MB\n","Epoch: [2/5][1400/6563] Loss: 0.5339(0.4342) Grad: 1.7591  LR: 0.000056  Elapsed: 7m 22s (remain 27m 10s) Max mem: 9779 MB\n","Epoch: [2/5][1500/6563] Loss: 0.4263(0.4346) Grad: 1.3673  LR: 0.000056  Elapsed: 7m 53s (remain 26m 37s) Max mem: 9779 MB\n","Epoch: [2/5][1600/6563] Loss: 0.5555(0.4348) Grad: 1.5307  LR: 0.000056  Elapsed: 8m 25s (remain 26m 6s) Max mem: 9779 MB\n","Epoch: [2/5][1700/6563] Loss: 0.4558(0.4348) Grad: 0.7839  LR: 0.000056  Elapsed: 8m 56s (remain 25m 34s) Max mem: 9779 MB\n","Epoch: [2/5][1800/6563] Loss: 0.3603(0.4348) Grad: 0.7720  LR: 0.000056  Elapsed: 9m 28s (remain 25m 2s) Max mem: 9779 MB\n","Epoch: [2/5][1900/6563] Loss: 0.4156(0.4347) Grad: 1.1929  LR: 0.000056  Elapsed: 9m 59s (remain 24m 30s) Max mem: 9779 MB\n","Epoch: [2/5][2000/6563] Loss: 0.3852(0.4346) Grad: 1.3542  LR: 0.000056  Elapsed: 10m 31s (remain 23m 59s) Max mem: 9779 MB\n","Epoch: [2/5][2100/6563] Loss: 0.5000(0.4346) Grad: 1.4993  LR: 0.000056  Elapsed: 11m 2s (remain 23m 26s) Max mem: 9779 MB\n","Epoch: [2/5][2200/6563] Loss: 0.4089(0.4350) Grad: 0.6621  LR: 0.000056  Elapsed: 11m 34s (remain 22m 55s) Max mem: 9779 MB\n","Epoch: [2/5][2300/6563] Loss: 0.3439(0.4349) Grad: 1.0100  LR: 0.000056  Elapsed: 12m 5s (remain 22m 23s) Max mem: 9779 MB\n","Epoch: [2/5][2400/6563] Loss: 0.4816(0.4348) Grad: 0.9861  LR: 0.000056  Elapsed: 12m 37s (remain 21m 52s) Max mem: 9779 MB\n","Epoch: [2/5][2500/6563] Loss: 0.5950(0.4349) Grad: 2.6019  LR: 0.000056  Elapsed: 13m 8s (remain 21m 20s) Max mem: 9779 MB\n","Epoch: [2/5][2600/6563] Loss: 0.3401(0.4352) Grad: 0.8681  LR: 0.000056  Elapsed: 13m 40s (remain 20m 49s) Max mem: 9779 MB\n","Epoch: [2/5][2700/6563] Loss: 0.4026(0.4347) Grad: 0.8472  LR: 0.000056  Elapsed: 14m 11s (remain 20m 18s) Max mem: 9779 MB\n","Epoch: [2/5][2800/6563] Loss: 0.4418(0.4350) Grad: 0.6996  LR: 0.000056  Elapsed: 14m 43s (remain 19m 46s) Max mem: 9779 MB\n","Epoch: [2/5][2900/6563] Loss: 0.4721(0.4351) Grad: 1.1442  LR: 0.000056  Elapsed: 15m 14s (remain 19m 15s) Max mem: 9779 MB\n","Epoch: [2/5][3000/6563] Loss: 0.4232(0.4350) Grad: 0.9907  LR: 0.000056  Elapsed: 15m 46s (remain 18m 43s) Max mem: 9779 MB\n","Epoch: [2/5][3100/6563] Loss: 0.4192(0.4350) Grad: 1.3393  LR: 0.000056  Elapsed: 16m 17s (remain 18m 11s) Max mem: 9779 MB\n","Epoch: [2/5][3200/6563] Loss: 0.4624(0.4350) Grad: 0.8417  LR: 0.000056  Elapsed: 16m 49s (remain 17m 39s) Max mem: 9779 MB\n","Epoch: [2/5][3300/6563] Loss: 0.4391(0.4350) Grad: 0.7981  LR: 0.000056  Elapsed: 17m 20s (remain 17m 8s) Max mem: 9779 MB\n","Epoch: [2/5][3400/6563] Loss: 0.3617(0.4345) Grad: 0.8888  LR: 0.000056  Elapsed: 17m 51s (remain 16m 36s) Max mem: 9779 MB\n","Epoch: [2/5][3500/6563] Loss: 0.3820(0.4343) Grad: 0.8334  LR: 0.000056  Elapsed: 18m 23s (remain 16m 4s) Max mem: 9779 MB\n","Epoch: [2/5][3600/6563] Loss: 0.4191(0.4342) Grad: 0.8425  LR: 0.000056  Elapsed: 18m 54s (remain 15m 33s) Max mem: 9779 MB\n","Epoch: [2/5][3700/6563] Loss: 0.3961(0.4339) Grad: 0.8971  LR: 0.000056  Elapsed: 19m 26s (remain 15m 1s) Max mem: 9779 MB\n","Epoch: [2/5][3800/6563] Loss: 0.4884(0.4338) Grad: 1.1759  LR: 0.000056  Elapsed: 19m 57s (remain 14m 30s) Max mem: 9779 MB\n","Epoch: [2/5][3900/6563] Loss: 0.4223(0.4337) Grad: 0.9684  LR: 0.000056  Elapsed: 20m 28s (remain 13m 58s) Max mem: 9779 MB\n","Epoch: [2/5][4000/6563] Loss: 0.3889(0.4334) Grad: 0.8382  LR: 0.000056  Elapsed: 21m 0s (remain 13m 27s) Max mem: 9779 MB\n","Epoch: [2/5][4100/6563] Loss: 0.5027(0.4333) Grad: 1.6093  LR: 0.000056  Elapsed: 21m 32s (remain 12m 55s) Max mem: 9779 MB\n","Epoch: [2/5][4200/6563] Loss: 0.3762(0.4330) Grad: 0.9792  LR: 0.000056  Elapsed: 22m 3s (remain 12m 24s) Max mem: 9779 MB\n","Epoch: [2/5][4300/6563] Loss: 0.3860(0.4328) Grad: 1.0985  LR: 0.000056  Elapsed: 22m 34s (remain 11m 52s) Max mem: 9779 MB\n","Epoch: [2/5][4400/6563] Loss: 0.6086(0.4328) Grad: 2.1682  LR: 0.000056  Elapsed: 23m 5s (remain 11m 20s) Max mem: 9779 MB\n","Epoch: [2/5][4500/6563] Loss: 0.4462(0.4327) Grad: 1.1440  LR: 0.000056  Elapsed: 23m 37s (remain 10m 49s) Max mem: 9779 MB\n","Epoch: [2/5][4600/6563] Loss: 0.4021(0.4327) Grad: 1.1225  LR: 0.000056  Elapsed: 24m 8s (remain 10m 17s) Max mem: 9779 MB\n","Epoch: [2/5][4700/6563] Loss: 0.4232(0.4327) Grad: 0.7670  LR: 0.000056  Elapsed: 24m 40s (remain 9m 46s) Max mem: 9779 MB\n","Epoch: [2/5][4800/6563] Loss: 0.4822(0.4328) Grad: 0.9642  LR: 0.000056  Elapsed: 25m 12s (remain 9m 15s) Max mem: 9779 MB\n","Epoch: [2/5][4900/6563] Loss: 0.5067(0.4327) Grad: 1.4009  LR: 0.000056  Elapsed: 25m 44s (remain 8m 43s) Max mem: 9779 MB\n","Epoch: [2/5][5000/6563] Loss: 0.3267(0.4324) Grad: 1.3141  LR: 0.000056  Elapsed: 26m 15s (remain 8m 12s) Max mem: 9779 MB\n","Epoch: [2/5][5100/6563] Loss: 0.4912(0.4323) Grad: 1.0695  LR: 0.000056  Elapsed: 26m 47s (remain 7m 40s) Max mem: 9779 MB\n","Epoch: [2/5][5200/6563] Loss: 0.4572(0.4322) Grad: 1.1303  LR: 0.000056  Elapsed: 27m 18s (remain 7m 9s) Max mem: 9779 MB\n","Epoch: [2/5][5300/6563] Loss: 0.3574(0.4321) Grad: 1.2357  LR: 0.000056  Elapsed: 27m 50s (remain 6m 37s) Max mem: 9779 MB\n","Epoch: [2/5][5400/6563] Loss: 0.4122(0.4320) Grad: 0.8186  LR: 0.000056  Elapsed: 28m 22s (remain 6m 6s) Max mem: 9779 MB\n","Epoch: [2/5][5500/6563] Loss: 0.4654(0.4319) Grad: 1.1909  LR: 0.000056  Elapsed: 28m 54s (remain 5m 34s) Max mem: 9779 MB\n","Epoch: [2/5][5600/6563] Loss: 0.3668(0.4320) Grad: 0.5798  LR: 0.000056  Elapsed: 29m 25s (remain 5m 3s) Max mem: 9779 MB\n","Epoch: [2/5][5700/6563] Loss: 0.5336(0.4319) Grad: 1.1958  LR: 0.000056  Elapsed: 29m 57s (remain 4m 31s) Max mem: 9779 MB\n","Epoch: [2/5][5800/6563] Loss: 0.5236(0.4321) Grad: 1.6629  LR: 0.000056  Elapsed: 30m 29s (remain 4m 0s) Max mem: 9779 MB\n","Epoch: [2/5][5900/6563] Loss: 0.4954(0.4321) Grad: 1.1468  LR: 0.000056  Elapsed: 31m 0s (remain 3m 28s) Max mem: 9779 MB\n","Epoch: [2/5][6000/6563] Loss: 0.5270(0.4320) Grad: 1.0244  LR: 0.000056  Elapsed: 31m 32s (remain 2m 57s) Max mem: 9779 MB\n","Epoch: [2/5][6100/6563] Loss: 0.4423(0.4321) Grad: 0.9777  LR: 0.000056  Elapsed: 32m 3s (remain 2m 25s) Max mem: 9779 MB\n","Epoch: [2/5][6200/6563] Loss: 0.4359(0.4319) Grad: 1.4894  LR: 0.000056  Elapsed: 32m 35s (remain 1m 54s) Max mem: 9779 MB\n","Epoch: [2/5][6300/6563] Loss: 0.4943(0.4317) Grad: 1.5595  LR: 0.000056  Elapsed: 33m 7s (remain 1m 22s) Max mem: 9779 MB\n","Epoch: [2/5][6400/6563] Loss: 0.4684(0.4317) Grad: 1.3916  LR: 0.000056  Elapsed: 33m 38s (remain 0m 51s) Max mem: 9779 MB\n","Epoch: [2/5][6500/6563] Loss: 0.4130(0.4316) Grad: 1.2982  LR: 0.000056  Elapsed: 34m 10s (remain 0m 19s) Max mem: 9779 MB\n","EVAL: [0/1094] Data 0.949 (0.949) Elapsed 0m 1s (remain 20m 12s) Loss: 0.4405(0.4405) \n","EVAL: [100/1094] Data 0.003 (0.015) Elapsed 0m 15s (remain 2m 36s) Loss: 0.5435(0.4285) \n","EVAL: [200/1094] Data 0.003 (0.009) Elapsed 0m 30s (remain 2m 15s) Loss: 0.3838(0.4340) \n","EVAL: [300/1094] Data 0.003 (0.007) Elapsed 0m 45s (remain 1m 58s) Loss: 0.3408(0.4326) \n","EVAL: [400/1094] Data 0.003 (0.006) Elapsed 0m 59s (remain 1m 43s) Loss: 0.3910(0.4309) \n","EVAL: [500/1094] Data 0.003 (0.006) Elapsed 1m 14s (remain 1m 27s) Loss: 0.4301(0.4313) \n","EVAL: [600/1094] Data 0.003 (0.005) Elapsed 1m 28s (remain 1m 12s) Loss: 0.4618(0.4314) \n","EVAL: [700/1094] Data 0.003 (0.008) Elapsed 1m 45s (remain 0m 59s) Loss: 0.4731(0.4305) \n","EVAL: [800/1094] Data 0.003 (0.008) Elapsed 2m 0s (remain 0m 44s) Loss: 0.4549(0.4305) \n","EVAL: [900/1094] Data 0.003 (0.008) Elapsed 2m 15s (remain 0m 28s) Loss: 0.4619(0.4306) \n","EVAL: [1000/1094] Data 0.003 (0.007) Elapsed 2m 29s (remain 0m 13s) Loss: 0.4561(0.4312) \n","Epoch 2 - avg_train_loss: 0.4316  avg_val_loss: 0.4303  time: 2238s\n","Epoch 2 - Score: 0.8598\n","Epoch 2 - Save Best Score: 0.8598 Model\n","Epoch 2 - Save Best Loss: 0.4303 Model\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch: [3/5][0/6563] Loss: 0.4489(0.4489) Grad: 1.0283  LR: 0.000008  Elapsed: 0m 1s (remain 145m 0s) Max mem: 9779 MB\n","Epoch: [3/5][100/6563] Loss: 0.3753(0.4293) Grad: 0.9420  LR: 0.000008  Elapsed: 0m 33s (remain 35m 27s) Max mem: 9779 MB\n","Epoch: [3/5][200/6563] Loss: 0.3979(0.4268) Grad: 1.9013  LR: 0.000008  Elapsed: 1m 5s (remain 34m 18s) Max mem: 9779 MB\n","Epoch: [3/5][300/6563] Loss: 0.4473(0.4240) Grad: 1.1347  LR: 0.000008  Elapsed: 1m 36s (remain 33m 28s) Max mem: 9779 MB\n","Epoch: [3/5][400/6563] Loss: 0.4458(0.4218) Grad: 1.2834  LR: 0.000008  Elapsed: 2m 7s (remain 32m 46s) Max mem: 9779 MB\n","Epoch: [3/5][500/6563] Loss: 0.4821(0.4230) Grad: 1.9203  LR: 0.000008  Elapsed: 2m 39s (remain 32m 10s) Max mem: 9779 MB\n","Epoch: [3/5][600/6563] Loss: 0.4012(0.4237) Grad: 1.3763  LR: 0.000008  Elapsed: 3m 10s (remain 31m 33s) Max mem: 9779 MB\n","Epoch: [3/5][700/6563] Loss: 0.4729(0.4232) Grad: 1.0853  LR: 0.000008  Elapsed: 3m 42s (remain 31m 0s) Max mem: 9779 MB\n","Epoch: [3/5][800/6563] Loss: 0.4688(0.4228) Grad: 1.9299  LR: 0.000008  Elapsed: 4m 13s (remain 30m 25s) Max mem: 9779 MB\n","Epoch: [3/5][900/6563] Loss: 0.3998(0.4227) Grad: 1.0363  LR: 0.000008  Elapsed: 4m 45s (remain 29m 52s) Max mem: 9779 MB\n","Epoch: [3/5][1000/6563] Loss: 0.5076(0.4219) Grad: 1.0699  LR: 0.000008  Elapsed: 5m 16s (remain 29m 20s) Max mem: 9779 MB\n","Epoch: [3/5][1100/6563] Loss: 0.3488(0.4229) Grad: 1.2987  LR: 0.000008  Elapsed: 5m 48s (remain 28m 48s) Max mem: 9779 MB\n","Epoch: [3/5][1200/6563] Loss: 0.4711(0.4231) Grad: 1.4683  LR: 0.000008  Elapsed: 6m 20s (remain 28m 17s) Max mem: 9779 MB\n","Epoch: [3/5][1300/6563] Loss: 0.4933(0.4230) Grad: 2.1955  LR: 0.000008  Elapsed: 6m 51s (remain 27m 45s) Max mem: 9779 MB\n","Epoch: [3/5][1400/6563] Loss: 0.4351(0.4236) Grad: 1.2852  LR: 0.000008  Elapsed: 7m 23s (remain 27m 13s) Max mem: 9779 MB\n","Epoch: [3/5][1500/6563] Loss: 0.4413(0.4240) Grad: 1.0852  LR: 0.000008  Elapsed: 7m 54s (remain 26m 41s) Max mem: 9779 MB\n","Epoch: [3/5][1600/6563] Loss: 0.4282(0.4236) Grad: 1.2370  LR: 0.000008  Elapsed: 8m 26s (remain 26m 9s) Max mem: 9779 MB\n","Epoch: [3/5][1700/6563] Loss: 0.4095(0.4240) Grad: 1.2239  LR: 0.000008  Elapsed: 8m 57s (remain 25m 37s) Max mem: 9779 MB\n","Epoch: [3/5][1800/6563] Loss: 0.4383(0.4243) Grad: 1.6856  LR: 0.000008  Elapsed: 9m 29s (remain 25m 5s) Max mem: 9779 MB\n","Epoch: [3/5][1900/6563] Loss: 0.2962(0.4239) Grad: 1.2437  LR: 0.000008  Elapsed: 10m 0s (remain 24m 33s) Max mem: 9779 MB\n","Epoch: [3/5][2000/6563] Loss: 0.4855(0.4240) Grad: 1.4604  LR: 0.000008  Elapsed: 10m 32s (remain 24m 1s) Max mem: 9779 MB\n","Epoch: [3/5][2100/6563] Loss: 0.4732(0.4242) Grad: 1.5288  LR: 0.000008  Elapsed: 11m 3s (remain 23m 29s) Max mem: 9779 MB\n","Epoch: [3/5][2200/6563] Loss: 0.4446(0.4243) Grad: 1.3056  LR: 0.000008  Elapsed: 11m 35s (remain 22m 58s) Max mem: 9779 MB\n","Epoch: [3/5][2300/6563] Loss: 0.4719(0.4244) Grad: 1.5041  LR: 0.000008  Elapsed: 12m 6s (remain 22m 26s) Max mem: 9779 MB\n","Epoch: [3/5][2400/6563] Loss: 0.3857(0.4241) Grad: 1.0350  LR: 0.000008  Elapsed: 12m 38s (remain 21m 54s) Max mem: 9779 MB\n","Epoch: [3/5][2500/6563] Loss: 0.3541(0.4243) Grad: 1.5790  LR: 0.000008  Elapsed: 13m 10s (remain 21m 23s) Max mem: 9779 MB\n","Epoch: [3/5][2600/6563] Loss: 0.3647(0.4243) Grad: 1.3054  LR: 0.000008  Elapsed: 13m 41s (remain 20m 51s) Max mem: 9779 MB\n","Epoch: [3/5][2700/6563] Loss: 0.4388(0.4241) Grad: 1.4073  LR: 0.000008  Elapsed: 14m 13s (remain 20m 19s) Max mem: 9779 MB\n","Epoch: [3/5][2800/6563] Loss: 0.4411(0.4244) Grad: 1.3120  LR: 0.000008  Elapsed: 14m 44s (remain 19m 48s) Max mem: 9779 MB\n","Epoch: [3/5][2900/6563] Loss: 0.4189(0.4245) Grad: 1.4665  LR: 0.000008  Elapsed: 15m 16s (remain 19m 16s) Max mem: 9779 MB\n","Epoch: [3/5][3000/6563] Loss: 0.2961(0.4244) Grad: 1.3471  LR: 0.000008  Elapsed: 15m 48s (remain 18m 45s) Max mem: 9779 MB\n","Epoch: [3/5][3100/6563] Loss: 0.3368(0.4243) Grad: 1.2558  LR: 0.000008  Elapsed: 16m 19s (remain 18m 13s) Max mem: 9779 MB\n","Epoch: [3/5][3200/6563] Loss: 0.5635(0.4244) Grad: 1.7356  LR: 0.000008  Elapsed: 16m 51s (remain 17m 42s) Max mem: 9779 MB\n","Epoch: [3/5][3300/6563] Loss: 0.3378(0.4243) Grad: 1.4661  LR: 0.000008  Elapsed: 17m 23s (remain 17m 10s) Max mem: 9779 MB\n","Epoch: [3/5][3400/6563] Loss: 0.3315(0.4240) Grad: 1.6401  LR: 0.000008  Elapsed: 17m 54s (remain 16m 39s) Max mem: 9779 MB\n","Epoch: [3/5][3500/6563] Loss: 0.3850(0.4239) Grad: 1.5828  LR: 0.000008  Elapsed: 18m 26s (remain 16m 7s) Max mem: 9779 MB\n","Epoch: [3/5][3600/6563] Loss: 0.5066(0.4236) Grad: 1.5871  LR: 0.000008  Elapsed: 18m 57s (remain 15m 35s) Max mem: 9779 MB\n","Epoch: [3/5][3700/6563] Loss: 0.3830(0.4235) Grad: 1.0298  LR: 0.000008  Elapsed: 19m 29s (remain 15m 4s) Max mem: 9779 MB\n","Epoch: [3/5][3800/6563] Loss: 0.3667(0.4234) Grad: 0.9066  LR: 0.000008  Elapsed: 20m 0s (remain 14m 32s) Max mem: 9779 MB\n","Epoch: [3/5][3900/6563] Loss: 0.4573(0.4232) Grad: 1.3961  LR: 0.000008  Elapsed: 20m 32s (remain 14m 0s) Max mem: 9779 MB\n","Epoch: [3/5][4000/6563] Loss: 0.3999(0.4231) Grad: 1.6937  LR: 0.000008  Elapsed: 21m 3s (remain 13m 29s) Max mem: 9779 MB\n","Epoch: [3/5][4100/6563] Loss: 0.3748(0.4229) Grad: 1.0168  LR: 0.000008  Elapsed: 21m 35s (remain 12m 57s) Max mem: 9779 MB\n","Epoch: [3/5][4200/6563] Loss: 0.4118(0.4228) Grad: 1.4156  LR: 0.000008  Elapsed: 22m 7s (remain 12m 26s) Max mem: 9779 MB\n","Epoch: [3/5][4300/6563] Loss: 0.3701(0.4225) Grad: 1.0102  LR: 0.000008  Elapsed: 22m 38s (remain 11m 54s) Max mem: 9779 MB\n","Epoch: [3/5][4400/6563] Loss: 0.4319(0.4223) Grad: 1.7427  LR: 0.000008  Elapsed: 23m 10s (remain 11m 22s) Max mem: 9779 MB\n","Epoch: [3/5][4500/6563] Loss: 0.4090(0.4224) Grad: 1.2529  LR: 0.000008  Elapsed: 23m 41s (remain 10m 51s) Max mem: 9779 MB\n","Epoch: [3/5][4600/6563] Loss: 0.4485(0.4225) Grad: 1.2096  LR: 0.000008  Elapsed: 24m 12s (remain 10m 19s) Max mem: 9779 MB\n","Epoch: [3/5][4700/6563] Loss: 0.3709(0.4225) Grad: 1.4156  LR: 0.000008  Elapsed: 24m 44s (remain 9m 47s) Max mem: 9779 MB\n","Epoch: [3/5][4800/6563] Loss: 0.4392(0.4225) Grad: 1.7900  LR: 0.000008  Elapsed: 25m 15s (remain 9m 16s) Max mem: 9779 MB\n","Epoch: [3/5][4900/6563] Loss: 0.3722(0.4224) Grad: 1.2013  LR: 0.000008  Elapsed: 25m 47s (remain 8m 44s) Max mem: 9779 MB\n","Epoch: [3/5][5000/6563] Loss: 0.4557(0.4222) Grad: 1.4630  LR: 0.000008  Elapsed: 26m 18s (remain 8m 13s) Max mem: 9779 MB\n","Epoch: [3/5][5100/6563] Loss: 0.3869(0.4220) Grad: 1.2807  LR: 0.000008  Elapsed: 26m 50s (remain 7m 41s) Max mem: 9779 MB\n","Epoch: [3/5][5200/6563] Loss: 0.4743(0.4219) Grad: 1.4004  LR: 0.000008  Elapsed: 27m 22s (remain 7m 10s) Max mem: 9779 MB\n","Epoch: [3/5][5300/6563] Loss: 0.4942(0.4218) Grad: 1.4677  LR: 0.000008  Elapsed: 27m 53s (remain 6m 38s) Max mem: 9779 MB\n","Epoch: [3/5][5400/6563] Loss: 0.3939(0.4217) Grad: 1.4803  LR: 0.000008  Elapsed: 28m 25s (remain 6m 6s) Max mem: 9779 MB\n","Epoch: [3/5][5500/6563] Loss: 0.4630(0.4217) Grad: 1.4851  LR: 0.000008  Elapsed: 28m 56s (remain 5m 35s) Max mem: 9779 MB\n","Epoch: [3/5][5600/6563] Loss: 0.4300(0.4217) Grad: 1.8209  LR: 0.000008  Elapsed: 29m 27s (remain 5m 3s) Max mem: 9779 MB\n","Epoch: [3/5][5700/6563] Loss: 0.5473(0.4217) Grad: 2.1754  LR: 0.000008  Elapsed: 29m 59s (remain 4m 32s) Max mem: 9779 MB\n","Epoch: [3/5][5800/6563] Loss: 0.4435(0.4218) Grad: 1.6515  LR: 0.000008  Elapsed: 30m 30s (remain 4m 0s) Max mem: 9779 MB\n","Epoch: [3/5][5900/6563] Loss: 0.3888(0.4218) Grad: 1.5444  LR: 0.000008  Elapsed: 31m 2s (remain 3m 28s) Max mem: 9779 MB\n","Epoch: [3/5][6000/6563] Loss: 0.4275(0.4218) Grad: 1.8798  LR: 0.000008  Elapsed: 31m 33s (remain 2m 57s) Max mem: 9779 MB\n","Epoch: [3/5][6100/6563] Loss: 0.4326(0.4217) Grad: 1.7703  LR: 0.000008  Elapsed: 32m 5s (remain 2m 25s) Max mem: 9779 MB\n","Epoch: [3/5][6200/6563] Loss: 0.4368(0.4216) Grad: 1.5282  LR: 0.000008  Elapsed: 32m 36s (remain 1m 54s) Max mem: 9779 MB\n","Epoch: [3/5][6300/6563] Loss: 0.3916(0.4215) Grad: 1.4317  LR: 0.000008  Elapsed: 33m 8s (remain 1m 22s) Max mem: 9779 MB\n","Epoch: [3/5][6400/6563] Loss: 0.3102(0.4214) Grad: 1.2637  LR: 0.000008  Elapsed: 33m 40s (remain 0m 51s) Max mem: 9779 MB\n","Epoch: [3/5][6500/6563] Loss: 0.3462(0.4213) Grad: 0.9154  LR: 0.000008  Elapsed: 34m 11s (remain 0m 19s) Max mem: 9779 MB\n","EVAL: [0/1094] Data 0.961 (0.961) Elapsed 0m 1s (remain 20m 25s) Loss: 0.4281(0.4281) \n","EVAL: [100/1094] Data 0.003 (0.013) Elapsed 0m 15s (remain 2m 34s) Loss: 0.5128(0.4228) \n","EVAL: [200/1094] Data 0.003 (0.008) Elapsed 0m 30s (remain 2m 14s) Loss: 0.4067(0.4279) \n","EVAL: [300/1094] Data 0.003 (0.006) Elapsed 0m 44s (remain 1m 58s) Loss: 0.3566(0.4259) \n","EVAL: [400/1094] Data 0.003 (0.006) Elapsed 0m 59s (remain 1m 42s) Loss: 0.4031(0.4249) \n","EVAL: [500/1094] Data 0.003 (0.005) Elapsed 1m 14s (remain 1m 27s) Loss: 0.4383(0.4250) \n","EVAL: [600/1094] Data 0.003 (0.005) Elapsed 1m 28s (remain 1m 12s) Loss: 0.4536(0.4254) \n","EVAL: [700/1094] Data 0.003 (0.005) Elapsed 1m 43s (remain 0m 57s) Loss: 0.4462(0.4247) \n","EVAL: [800/1094] Data 0.003 (0.004) Elapsed 1m 57s (remain 0m 43s) Loss: 0.4320(0.4248) \n","EVAL: [900/1094] Data 0.003 (0.004) Elapsed 2m 12s (remain 0m 28s) Loss: 0.4669(0.4250) \n","EVAL: [1000/1094] Data 0.003 (0.004) Elapsed 2m 26s (remain 0m 13s) Loss: 0.4297(0.4256) \n","Epoch 3 - avg_train_loss: 0.4214  avg_val_loss: 0.4248  time: 2237s\n","Epoch 3 - Score: 0.8627\n","Epoch 3 - Save Best Score: 0.8627 Model\n","Epoch 3 - Save Best Loss: 0.4248 Model\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch: [4/5][0/6563] Loss: 0.4049(0.4049) Grad: 1.4271  LR: 0.000000  Elapsed: 0m 0s (remain 102m 52s) Max mem: 9779 MB\n","Epoch: [4/5][100/6563] Loss: 0.3220(0.4293) Grad: 1.4376  LR: 0.000000  Elapsed: 0m 32s (remain 34m 38s) Max mem: 9779 MB\n","Epoch: [4/5][200/6563] Loss: 0.3961(0.4264) Grad: 1.4608  LR: 0.000000  Elapsed: 1m 4s (remain 33m 47s) Max mem: 9779 MB\n","Epoch: [4/5][300/6563] Loss: 0.4087(0.4206) Grad: 1.2676  LR: 0.000000  Elapsed: 1m 35s (remain 33m 5s) Max mem: 9779 MB\n","Epoch: [4/5][400/6563] Loss: 0.5140(0.4211) Grad: 1.7764  LR: 0.000000  Elapsed: 2m 6s (remain 32m 28s) Max mem: 9779 MB\n","Epoch: [4/5][500/6563] Loss: 0.3344(0.4194) Grad: 0.9881  LR: 0.000000  Elapsed: 2m 38s (remain 31m 54s) Max mem: 9779 MB\n","Epoch: [4/5][600/6563] Loss: 0.4177(0.4205) Grad: 1.5669  LR: 0.000000  Elapsed: 3m 9s (remain 31m 21s) Max mem: 9779 MB\n","Epoch: [4/5][700/6563] Loss: 0.5538(0.4195) Grad: 3.2125  LR: 0.000000  Elapsed: 3m 41s (remain 30m 49s) Max mem: 9779 MB\n","Epoch: [4/5][800/6563] Loss: 0.4381(0.4193) Grad: 1.1085  LR: 0.000000  Elapsed: 4m 13s (remain 30m 20s) Max mem: 9779 MB\n","Epoch: [4/5][900/6563] Loss: 0.4541(0.4197) Grad: 1.3021  LR: 0.000000  Elapsed: 4m 44s (remain 29m 47s) Max mem: 9779 MB\n","Epoch: [4/5][1000/6563] Loss: 0.4361(0.4201) Grad: 1.2826  LR: 0.000000  Elapsed: 5m 15s (remain 29m 15s) Max mem: 9779 MB\n","Epoch: [4/5][1100/6563] Loss: 0.4154(0.4204) Grad: 1.4584  LR: 0.000000  Elapsed: 5m 47s (remain 28m 42s) Max mem: 9779 MB\n","Epoch: [4/5][1200/6563] Loss: 0.4141(0.4204) Grad: 1.4215  LR: 0.000000  Elapsed: 6m 18s (remain 28m 11s) Max mem: 9779 MB\n","Epoch: [4/5][1300/6563] Loss: 0.4354(0.4205) Grad: 1.6092  LR: 0.000000  Elapsed: 6m 50s (remain 27m 39s) Max mem: 9779 MB\n","Epoch: [4/5][1400/6563] Loss: 0.4144(0.4208) Grad: 1.3825  LR: 0.000000  Elapsed: 7m 22s (remain 27m 8s) Max mem: 9779 MB\n","Epoch: [4/5][1500/6563] Loss: 0.4891(0.4211) Grad: 1.6038  LR: 0.000000  Elapsed: 7m 53s (remain 26m 36s) Max mem: 9779 MB\n","Epoch: [4/5][1600/6563] Loss: 0.3904(0.4208) Grad: 1.5721  LR: 0.000000  Elapsed: 8m 24s (remain 26m 3s) Max mem: 9779 MB\n","Epoch: [4/5][1700/6563] Loss: 0.3684(0.4209) Grad: 1.6195  LR: 0.000000  Elapsed: 8m 55s (remain 25m 31s) Max mem: 9779 MB\n","Epoch: [4/5][1800/6563] Loss: 0.3120(0.4213) Grad: 1.5922  LR: 0.000000  Elapsed: 9m 27s (remain 25m 0s) Max mem: 9779 MB\n","Epoch: [4/5][1900/6563] Loss: 0.4612(0.4210) Grad: 1.6727  LR: 0.000000  Elapsed: 9m 59s (remain 24m 29s) Max mem: 9779 MB\n","Epoch: [4/5][2000/6563] Loss: 0.4088(0.4212) Grad: 1.2744  LR: 0.000000  Elapsed: 10m 30s (remain 23m 58s) Max mem: 9779 MB\n","Epoch: [4/5][2100/6563] Loss: 0.3570(0.4212) Grad: 1.4331  LR: 0.000000  Elapsed: 11m 2s (remain 23m 25s) Max mem: 9779 MB\n","Epoch: [4/5][2200/6563] Loss: 0.3725(0.4216) Grad: 1.4886  LR: 0.000000  Elapsed: 11m 33s (remain 22m 54s) Max mem: 9779 MB\n","Epoch: [4/5][2300/6563] Loss: 0.4876(0.4216) Grad: 1.6780  LR: 0.000000  Elapsed: 12m 4s (remain 22m 22s) Max mem: 9779 MB\n","Epoch: [4/5][2400/6563] Loss: 0.6264(0.4212) Grad: 4.0178  LR: 0.000000  Elapsed: 12m 36s (remain 21m 50s) Max mem: 9779 MB\n","Epoch: [4/5][2500/6563] Loss: 0.4868(0.4216) Grad: 1.7534  LR: 0.000000  Elapsed: 13m 7s (remain 21m 19s) Max mem: 9779 MB\n","Epoch: [4/5][2600/6563] Loss: 0.5416(0.4215) Grad: 1.9464  LR: 0.000000  Elapsed: 13m 39s (remain 20m 47s) Max mem: 9779 MB\n","Epoch: [4/5][2700/6563] Loss: 0.3434(0.4212) Grad: 1.6860  LR: 0.000000  Elapsed: 14m 10s (remain 20m 16s) Max mem: 9779 MB\n","Epoch: [4/5][2800/6563] Loss: 0.4164(0.4213) Grad: 1.6890  LR: 0.000000  Elapsed: 14m 42s (remain 19m 44s) Max mem: 9779 MB\n","Epoch: [4/5][2900/6563] Loss: 0.5173(0.4217) Grad: 1.5374  LR: 0.000000  Elapsed: 15m 13s (remain 19m 13s) Max mem: 9779 MB\n","Epoch: [4/5][3000/6563] Loss: 0.3680(0.4214) Grad: 1.2166  LR: 0.000000  Elapsed: 15m 44s (remain 18m 41s) Max mem: 9779 MB\n","Epoch: [4/5][3100/6563] Loss: 0.5166(0.4214) Grad: 2.5026  LR: 0.000000  Elapsed: 16m 16s (remain 18m 9s) Max mem: 9779 MB\n","Epoch: [4/5][3200/6563] Loss: 0.3615(0.4215) Grad: 1.8571  LR: 0.000000  Elapsed: 16m 47s (remain 17m 38s) Max mem: 9779 MB\n","Epoch: [4/5][3300/6563] Loss: 0.4169(0.4214) Grad: 1.4400  LR: 0.000000  Elapsed: 17m 19s (remain 17m 7s) Max mem: 9779 MB\n","Epoch: [4/5][3400/6563] Loss: 0.4146(0.4212) Grad: 2.1050  LR: 0.000000  Elapsed: 17m 50s (remain 16m 35s) Max mem: 9779 MB\n","Epoch: [4/5][3500/6563] Loss: 0.4510(0.4210) Grad: 3.0705  LR: 0.000000  Elapsed: 18m 22s (remain 16m 4s) Max mem: 9779 MB\n","Epoch: [4/5][3600/6563] Loss: 0.2918(0.4206) Grad: 1.4359  LR: 0.000000  Elapsed: 18m 53s (remain 15m 32s) Max mem: 9779 MB\n","Epoch: [4/5][3700/6563] Loss: 0.4468(0.4207) Grad: 1.6760  LR: 0.000000  Elapsed: 19m 25s (remain 15m 1s) Max mem: 9779 MB\n","Epoch: [4/5][3800/6563] Loss: 0.3440(0.4202) Grad: 1.2378  LR: 0.000000  Elapsed: 19m 57s (remain 14m 29s) Max mem: 9779 MB\n","Epoch: [4/5][3900/6563] Loss: 0.4388(0.4201) Grad: 1.8709  LR: 0.000000  Elapsed: 20m 28s (remain 13m 58s) Max mem: 9779 MB\n","Epoch: [4/5][4000/6563] Loss: 0.3175(0.4200) Grad: 1.3335  LR: 0.000000  Elapsed: 20m 59s (remain 13m 26s) Max mem: 9779 MB\n","Epoch: [4/5][4100/6563] Loss: 0.4147(0.4198) Grad: 1.3950  LR: 0.000000  Elapsed: 21m 31s (remain 12m 55s) Max mem: 9779 MB\n","Epoch: [4/5][4200/6563] Loss: 0.5102(0.4196) Grad: 1.8315  LR: 0.000000  Elapsed: 22m 2s (remain 12m 23s) Max mem: 9779 MB\n","Epoch: [4/5][4300/6563] Loss: 0.4910(0.4193) Grad: 1.7503  LR: 0.000000  Elapsed: 22m 34s (remain 11m 52s) Max mem: 9779 MB\n","Epoch: [4/5][4400/6563] Loss: 0.4344(0.4193) Grad: 1.6941  LR: 0.000000  Elapsed: 23m 5s (remain 11m 20s) Max mem: 9779 MB\n","Epoch: [4/5][4500/6563] Loss: 0.4065(0.4192) Grad: 1.4897  LR: 0.000000  Elapsed: 23m 37s (remain 10m 49s) Max mem: 9779 MB\n","Epoch: [4/5][4600/6563] Loss: 0.4860(0.4193) Grad: 2.1331  LR: 0.000000  Elapsed: 24m 9s (remain 10m 17s) Max mem: 9779 MB\n","Epoch: [4/5][4700/6563] Loss: 0.4056(0.4192) Grad: 1.6727  LR: 0.000000  Elapsed: 24m 40s (remain 9m 46s) Max mem: 9779 MB\n","Epoch: [4/5][4800/6563] Loss: 0.4718(0.4192) Grad: 1.8014  LR: 0.000000  Elapsed: 25m 12s (remain 9m 15s) Max mem: 9779 MB\n","Epoch: [4/5][4900/6563] Loss: 0.3526(0.4192) Grad: 1.3113  LR: 0.000000  Elapsed: 25m 43s (remain 8m 43s) Max mem: 9779 MB\n","Epoch: [4/5][5000/6563] Loss: 0.4493(0.4189) Grad: 1.5591  LR: 0.000000  Elapsed: 26m 15s (remain 8m 12s) Max mem: 9779 MB\n","Epoch: [4/5][5100/6563] Loss: 0.4481(0.4188) Grad: 1.7791  LR: 0.000000  Elapsed: 26m 47s (remain 7m 40s) Max mem: 9779 MB\n","Epoch: [4/5][5200/6563] Loss: 0.2929(0.4187) Grad: 1.3622  LR: 0.000000  Elapsed: 27m 18s (remain 7m 9s) Max mem: 9779 MB\n","Epoch: [4/5][5300/6563] Loss: 0.4027(0.4185) Grad: 2.0008  LR: 0.000000  Elapsed: 27m 50s (remain 6m 37s) Max mem: 9779 MB\n","Epoch: [4/5][5400/6563] Loss: 0.4047(0.4184) Grad: 1.5667  LR: 0.000000  Elapsed: 28m 21s (remain 6m 6s) Max mem: 9779 MB\n","Epoch: [4/5][5500/6563] Loss: 0.4727(0.4183) Grad: 2.3189  LR: 0.000000  Elapsed: 28m 53s (remain 5m 34s) Max mem: 9779 MB\n","Epoch: [4/5][5600/6563] Loss: 0.4414(0.4184) Grad: 1.3204  LR: 0.000000  Elapsed: 29m 25s (remain 5m 3s) Max mem: 9779 MB\n","Epoch: [4/5][5700/6563] Loss: 0.4319(0.4183) Grad: 1.4303  LR: 0.000000  Elapsed: 29m 56s (remain 4m 31s) Max mem: 9779 MB\n","Epoch: [4/5][5800/6563] Loss: 0.4113(0.4183) Grad: 1.4636  LR: 0.000000  Elapsed: 30m 28s (remain 4m 0s) Max mem: 9779 MB\n","Epoch: [4/5][5900/6563] Loss: 0.5260(0.4183) Grad: 1.7795  LR: 0.000000  Elapsed: 30m 59s (remain 3m 28s) Max mem: 9779 MB\n","Epoch: [4/5][6000/6563] Loss: 0.4283(0.4182) Grad: 1.2301  LR: 0.000000  Elapsed: 31m 31s (remain 2m 57s) Max mem: 9779 MB\n","Epoch: [4/5][6100/6563] Loss: 0.4069(0.4181) Grad: 1.2992  LR: 0.000000  Elapsed: 32m 2s (remain 2m 25s) Max mem: 9779 MB\n","Epoch: [4/5][6200/6563] Loss: 0.4321(0.4181) Grad: 1.5594  LR: 0.000000  Elapsed: 32m 34s (remain 1m 54s) Max mem: 9779 MB\n","Epoch: [4/5][6300/6563] Loss: 0.3467(0.4177) Grad: 1.3742  LR: 0.000000  Elapsed: 33m 6s (remain 1m 22s) Max mem: 9779 MB\n","Epoch: [4/5][6400/6563] Loss: 0.3011(0.4177) Grad: 1.2715  LR: 0.000000  Elapsed: 33m 37s (remain 0m 51s) Max mem: 9779 MB\n","Epoch: [4/5][6500/6563] Loss: 0.4001(0.4175) Grad: 1.6351  LR: 0.000000  Elapsed: 34m 9s (remain 0m 19s) Max mem: 9779 MB\n","EVAL: [0/1094] Data 0.939 (0.939) Elapsed 0m 1s (remain 20m 1s) Loss: 0.4257(0.4257) \n","EVAL: [100/1094] Data 0.003 (0.012) Elapsed 0m 15s (remain 2m 34s) Loss: 0.5230(0.4199) \n","EVAL: [200/1094] Data 0.003 (0.008) Elapsed 0m 30s (remain 2m 14s) Loss: 0.3968(0.4256) \n","EVAL: [300/1094] Data 0.003 (0.006) Elapsed 0m 44s (remain 1m 58s) Loss: 0.3427(0.4237) \n","EVAL: [400/1094] Data 0.003 (0.005) Elapsed 0m 59s (remain 1m 42s) Loss: 0.3966(0.4225) \n","EVAL: [500/1094] Data 0.004 (0.005) Elapsed 1m 13s (remain 1m 27s) Loss: 0.4316(0.4227) \n","EVAL: [600/1094] Data 0.003 (0.005) Elapsed 1m 28s (remain 1m 12s) Loss: 0.4515(0.4231) \n","EVAL: [700/1094] Data 0.003 (0.004) Elapsed 1m 43s (remain 0m 57s) Loss: 0.4494(0.4223) \n","EVAL: [800/1094] Data 0.003 (0.004) Elapsed 1m 57s (remain 0m 43s) Loss: 0.4349(0.4224) \n","EVAL: [900/1094] Data 0.003 (0.004) Elapsed 2m 12s (remain 0m 28s) Loss: 0.4683(0.4227) \n","EVAL: [1000/1094] Data 0.003 (0.004) Elapsed 2m 26s (remain 0m 13s) Loss: 0.4268(0.4233) \n","Epoch 4 - avg_train_loss: 0.4175  avg_val_loss: 0.4224  time: 2235s\n","Epoch 4 - Score: 0.8634\n","Epoch 4 - Save Best Score: 0.8634 Model\n","Epoch 4 - Save Best Loss: 0.4224 Model\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","Epoch: [5/5][0/6563] Loss: 0.3283(0.3283) Grad: 1.4882  LR: 0.000050  Elapsed: 0m 1s (remain 121m 18s) Max mem: 9779 MB\n","Epoch: [5/5][100/6563] Loss: 0.3815(0.4299) Grad: 1.4631  LR: 0.000050  Elapsed: 0m 32s (remain 34m 59s) Max mem: 9779 MB\n","Epoch: [5/5][200/6563] Loss: 0.3715(0.4217) Grad: 2.1012  LR: 0.000050  Elapsed: 1m 4s (remain 33m 53s) Max mem: 9779 MB\n","Epoch: [5/5][300/6563] Loss: 0.3719(0.4186) Grad: 1.4251  LR: 0.000050  Elapsed: 1m 35s (remain 33m 16s) Max mem: 9779 MB\n","Epoch: [5/5][400/6563] Loss: 0.5113(0.4198) Grad: 1.6527  LR: 0.000050  Elapsed: 2m 7s (remain 32m 35s) Max mem: 9779 MB\n","Epoch: [5/5][500/6563] Loss: 0.4906(0.4192) Grad: 2.3969  LR: 0.000050  Elapsed: 2m 38s (remain 32m 2s) Max mem: 9779 MB\n","Epoch: [5/5][600/6563] Loss: 0.3942(0.4189) Grad: 1.8422  LR: 0.000050  Elapsed: 3m 10s (remain 31m 31s) Max mem: 9779 MB\n","Epoch: [5/5][700/6563] Loss: 0.3886(0.4192) Grad: 1.3439  LR: 0.000050  Elapsed: 3m 41s (remain 30m 55s) Max mem: 9779 MB\n","Epoch: [5/5][800/6563] Loss: 0.4748(0.4196) Grad: 2.4557  LR: 0.000050  Elapsed: 4m 13s (remain 30m 22s) Max mem: 9779 MB\n","Epoch: [5/5][900/6563] Loss: 0.3411(0.4198) Grad: 1.2579  LR: 0.000050  Elapsed: 4m 45s (remain 29m 51s) Max mem: 9779 MB\n","Epoch: [5/5][1000/6563] Loss: 0.4770(0.4196) Grad: 1.7936  LR: 0.000050  Elapsed: 5m 16s (remain 29m 17s) Max mem: 9779 MB\n","Epoch: [5/5][1100/6563] Loss: 0.4547(0.4204) Grad: 1.4084  LR: 0.000050  Elapsed: 5m 48s (remain 28m 47s) Max mem: 9779 MB\n","Epoch: [5/5][1200/6563] Loss: 0.4636(0.4199) Grad: 1.8029  LR: 0.000050  Elapsed: 6m 19s (remain 28m 15s) Max mem: 9779 MB\n","Epoch: [5/5][1300/6563] Loss: 0.4220(0.4206) Grad: 0.9932  LR: 0.000050  Elapsed: 6m 51s (remain 27m 43s) Max mem: 9779 MB\n","Epoch: [5/5][1400/6563] Loss: 0.4212(0.4211) Grad: 1.5065  LR: 0.000050  Elapsed: 7m 22s (remain 27m 11s) Max mem: 9779 MB\n","Epoch: [5/5][1500/6563] Loss: 0.4190(0.4210) Grad: 1.5776  LR: 0.000050  Elapsed: 7m 54s (remain 26m 39s) Max mem: 9779 MB\n","Epoch: [5/5][1600/6563] Loss: 0.4091(0.4210) Grad: 1.6039  LR: 0.000050  Elapsed: 8m 25s (remain 26m 8s) Max mem: 9779 MB\n","Epoch: [5/5][1700/6563] Loss: 0.4912(0.4212) Grad: 1.6014  LR: 0.000050  Elapsed: 8m 57s (remain 25m 35s) Max mem: 9779 MB\n","Epoch: [5/5][1800/6563] Loss: 0.3592(0.4212) Grad: 1.2767  LR: 0.000050  Elapsed: 9m 28s (remain 25m 3s) Max mem: 9779 MB\n","Epoch: [5/5][1900/6563] Loss: 0.3565(0.4212) Grad: 1.8918  LR: 0.000050  Elapsed: 10m 0s (remain 24m 31s) Max mem: 9779 MB\n","Epoch: [5/5][2000/6563] Loss: 0.4744(0.4212) Grad: 2.8496  LR: 0.000050  Elapsed: 10m 31s (remain 23m 59s) Max mem: 9779 MB\n","Epoch: [5/5][2100/6563] Loss: 0.4105(0.4209) Grad: 1.6114  LR: 0.000050  Elapsed: 11m 2s (remain 23m 27s) Max mem: 9779 MB\n","Epoch: [5/5][2200/6563] Loss: 0.4745(0.4216) Grad: 1.6387  LR: 0.000050  Elapsed: 11m 34s (remain 22m 56s) Max mem: 9779 MB\n","Epoch: [5/5][2300/6563] Loss: 0.4195(0.4215) Grad: 1.6119  LR: 0.000050  Elapsed: 12m 6s (remain 22m 24s) Max mem: 9779 MB\n","Epoch: [5/5][2400/6563] Loss: 0.3717(0.4214) Grad: 1.1752  LR: 0.000050  Elapsed: 12m 37s (remain 21m 53s) Max mem: 9779 MB\n","Epoch: [5/5][2500/6563] Loss: 0.3804(0.4214) Grad: 1.5730  LR: 0.000050  Elapsed: 13m 9s (remain 21m 21s) Max mem: 9779 MB\n","Epoch: [5/5][2600/6563] Loss: 0.5445(0.4218) Grad: 2.1806  LR: 0.000050  Elapsed: 13m 40s (remain 20m 50s) Max mem: 9779 MB\n","Epoch: [5/5][2700/6563] Loss: 0.3872(0.4214) Grad: 1.3619  LR: 0.000050  Elapsed: 14m 12s (remain 20m 18s) Max mem: 9779 MB\n","Epoch: [5/5][2800/6563] Loss: 0.4363(0.4217) Grad: 1.4561  LR: 0.000050  Elapsed: 14m 43s (remain 19m 47s) Max mem: 9779 MB\n","Epoch: [5/5][2900/6563] Loss: 0.4799(0.4218) Grad: 1.7219  LR: 0.000050  Elapsed: 15m 15s (remain 19m 15s) Max mem: 9779 MB\n","Epoch: [5/5][3000/6563] Loss: 0.4252(0.4217) Grad: 1.3082  LR: 0.000050  Elapsed: 15m 47s (remain 18m 44s) Max mem: 9779 MB\n","Epoch: [5/5][3100/6563] Loss: 0.3762(0.4215) Grad: 1.7593  LR: 0.000050  Elapsed: 16m 18s (remain 18m 12s) Max mem: 9779 MB\n","Epoch: [5/5][3200/6563] Loss: 0.4448(0.4218) Grad: 1.2083  LR: 0.000050  Elapsed: 16m 50s (remain 17m 41s) Max mem: 9779 MB\n","Epoch: [5/5][3300/6563] Loss: 0.4271(0.4216) Grad: 1.8785  LR: 0.000050  Elapsed: 17m 22s (remain 17m 9s) Max mem: 9779 MB\n","Epoch: [5/5][3400/6563] Loss: 0.3347(0.4213) Grad: 1.4033  LR: 0.000050  Elapsed: 17m 53s (remain 16m 38s) Max mem: 9779 MB\n","Epoch: [5/5][3500/6563] Loss: 0.3497(0.4212) Grad: 1.0572  LR: 0.000050  Elapsed: 18m 25s (remain 16m 6s) Max mem: 9779 MB\n","Epoch: [5/5][3600/6563] Loss: 0.4127(0.4209) Grad: 1.2452  LR: 0.000050  Elapsed: 18m 56s (remain 15m 34s) Max mem: 9779 MB\n","Epoch: [5/5][3700/6563] Loss: 0.3633(0.4209) Grad: 1.4944  LR: 0.000050  Elapsed: 19m 28s (remain 15m 3s) Max mem: 9779 MB\n","Epoch: [5/5][3800/6563] Loss: 0.3926(0.4206) Grad: 1.4626  LR: 0.000050  Elapsed: 19m 59s (remain 14m 31s) Max mem: 9779 MB\n","Epoch: [5/5][3900/6563] Loss: 0.4352(0.4205) Grad: 1.4569  LR: 0.000050  Elapsed: 20m 31s (remain 14m 0s) Max mem: 9779 MB\n","Epoch: [5/5][4000/6563] Loss: 0.5096(0.4206) Grad: 1.8710  LR: 0.000050  Elapsed: 21m 2s (remain 13m 28s) Max mem: 9779 MB\n","Epoch: [5/5][4100/6563] Loss: 0.3694(0.4204) Grad: 1.5050  LR: 0.000050  Elapsed: 21m 33s (remain 12m 56s) Max mem: 9779 MB\n","Epoch: [5/5][4200/6563] Loss: 0.3385(0.4200) Grad: 1.8953  LR: 0.000050  Elapsed: 22m 5s (remain 12m 25s) Max mem: 9779 MB\n","Epoch: [5/5][4300/6563] Loss: 0.5261(0.4199) Grad: 2.2015  LR: 0.000050  Elapsed: 22m 36s (remain 11m 53s) Max mem: 9779 MB\n","Epoch: [5/5][4400/6563] Loss: 0.3593(0.4197) Grad: 1.6719  LR: 0.000050  Elapsed: 23m 8s (remain 11m 21s) Max mem: 9779 MB\n","Epoch: [5/5][4500/6563] Loss: 0.3862(0.4198) Grad: 1.4125  LR: 0.000050  Elapsed: 23m 39s (remain 10m 50s) Max mem: 9779 MB\n","Epoch: [5/5][4600/6563] Loss: 0.2997(0.4198) Grad: 2.2001  LR: 0.000050  Elapsed: 24m 11s (remain 10m 18s) Max mem: 9779 MB\n","Epoch: [5/5][4700/6563] Loss: 0.4205(0.4199) Grad: 1.2111  LR: 0.000050  Elapsed: 24m 42s (remain 9m 47s) Max mem: 9779 MB\n","Epoch: [5/5][4800/6563] Loss: 0.3824(0.4198) Grad: 1.6891  LR: 0.000050  Elapsed: 25m 14s (remain 9m 15s) Max mem: 9779 MB\n","Epoch: [5/5][4900/6563] Loss: 0.5089(0.4199) Grad: 1.4723  LR: 0.000050  Elapsed: 25m 46s (remain 8m 44s) Max mem: 9779 MB\n","Epoch: [5/5][5000/6563] Loss: 0.4723(0.4196) Grad: 1.9734  LR: 0.000050  Elapsed: 26m 17s (remain 8m 12s) Max mem: 9779 MB\n","Epoch: [5/5][5100/6563] Loss: 0.4117(0.4194) Grad: 1.7515  LR: 0.000050  Elapsed: 26m 48s (remain 7m 41s) Max mem: 9779 MB\n","Epoch: [5/5][5200/6563] Loss: 0.4851(0.4193) Grad: 2.5413  LR: 0.000050  Elapsed: 27m 20s (remain 7m 9s) Max mem: 9779 MB\n","Epoch: [5/5][5300/6563] Loss: 0.3689(0.4195) Grad: 1.7182  LR: 0.000050  Elapsed: 27m 51s (remain 6m 37s) Max mem: 9779 MB\n","Epoch: [5/5][5400/6563] Loss: 0.3993(0.4193) Grad: 1.5303  LR: 0.000050  Elapsed: 28m 22s (remain 6m 6s) Max mem: 9779 MB\n","Epoch: [5/5][5500/6563] Loss: 0.3778(0.4192) Grad: 1.5461  LR: 0.000050  Elapsed: 28m 54s (remain 5m 34s) Max mem: 9779 MB\n","Epoch: [5/5][5600/6563] Loss: 0.4054(0.4194) Grad: 1.5775  LR: 0.000050  Elapsed: 29m 25s (remain 5m 3s) Max mem: 9779 MB\n","Epoch: [5/5][5700/6563] Loss: 0.3393(0.4193) Grad: 1.4523  LR: 0.000050  Elapsed: 29m 57s (remain 4m 31s) Max mem: 9779 MB\n","Epoch: [5/5][5800/6563] Loss: 0.4565(0.4193) Grad: 2.1674  LR: 0.000050  Elapsed: 30m 29s (remain 4m 0s) Max mem: 9779 MB\n","Epoch: [5/5][5900/6563] Loss: 0.4099(0.4194) Grad: 1.6234  LR: 0.000050  Elapsed: 31m 0s (remain 3m 28s) Max mem: 9779 MB\n","Epoch: [5/5][6000/6563] Loss: 0.4016(0.4193) Grad: 1.3446  LR: 0.000050  Elapsed: 31m 32s (remain 2m 57s) Max mem: 9779 MB\n","Epoch: [5/5][6100/6563] Loss: 0.3392(0.4193) Grad: 1.2394  LR: 0.000050  Elapsed: 32m 3s (remain 2m 25s) Max mem: 9779 MB\n","Epoch: [5/5][6200/6563] Loss: 0.4740(0.4192) Grad: 2.3132  LR: 0.000050  Elapsed: 32m 35s (remain 1m 54s) Max mem: 9779 MB\n","Epoch: [5/5][6300/6563] Loss: 0.4054(0.4192) Grad: 1.9914  LR: 0.000050  Elapsed: 33m 6s (remain 1m 22s) Max mem: 9779 MB\n","Epoch: [5/5][6400/6563] Loss: 0.4194(0.4191) Grad: 1.4415  LR: 0.000050  Elapsed: 33m 38s (remain 0m 51s) Max mem: 9779 MB\n","Epoch: [5/5][6500/6563] Loss: 0.4176(0.4190) Grad: 1.9028  LR: 0.000050  Elapsed: 34m 10s (remain 0m 19s) Max mem: 9779 MB\n","EVAL: [0/1094] Data 1.290 (1.290) Elapsed 0m 1s (remain 26m 25s) Loss: 0.4210(0.4210) \n","EVAL: [100/1094] Data 0.003 (0.019) Elapsed 0m 16s (remain 2m 41s) Loss: 0.5158(0.4206) \n","EVAL: [200/1094] Data 0.003 (0.011) Elapsed 0m 30s (remain 2m 17s) Loss: 0.3888(0.4257) \n","EVAL: [300/1094] Data 0.003 (0.009) Elapsed 0m 45s (remain 2m 0s) Loss: 0.3468(0.4240) \n","EVAL: [400/1094] Data 0.003 (0.007) Elapsed 1m 0s (remain 1m 43s) Loss: 0.3981(0.4227) \n","EVAL: [500/1094] Data 0.003 (0.006) Elapsed 1m 14s (remain 1m 28s) Loss: 0.4296(0.4229) \n","EVAL: [600/1094] Data 0.003 (0.006) Elapsed 1m 29s (remain 1m 13s) Loss: 0.4455(0.4231) \n","EVAL: [700/1094] Data 0.003 (0.006) Elapsed 1m 43s (remain 0m 58s) Loss: 0.4508(0.4224) \n","EVAL: [800/1094] Data 0.003 (0.005) Elapsed 1m 58s (remain 0m 43s) Loss: 0.4319(0.4224) \n","EVAL: [900/1094] Data 0.003 (0.005) Elapsed 2m 13s (remain 0m 28s) Loss: 0.4500(0.4226) \n","EVAL: [1000/1094] Data 0.003 (0.005) Elapsed 2m 27s (remain 0m 13s) Loss: 0.4249(0.4232) \n","Epoch 5 - avg_train_loss: 0.4191  avg_val_loss: 0.4223  time: 2236s\n","Epoch 5 - Score: 0.8637\n","Epoch 5 - Save Best Score: 0.8637 Model\n","Epoch 5 - Save Best Loss: 0.4223 Model\n","========== fold: 0 result ==========\n","Score: 0.8637\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W\u0026B process to finish, PID 1953\n","\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/006/wandb/run-20210921_080157-3c8qpmu5/logs/debug.log\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/006/wandb/run-20210921_080157-3c8qpmu5/logs/debug-internal.log\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   avg_train_loss 0.41907\n","\u001b[34m\u001b[1mwandb\u001b[0m:     avg_val_loss 0.42235\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch 5\n","\u001b[34m\u001b[1mwandb\u001b[0m:             loss 0.52107\n","\u001b[34m\u001b[1mwandb\u001b[0m:               lr 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m:            score 0.8637\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   avg_train_loss █▃▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     avg_val_loss █▃▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            epoch ▁▃▅▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:             loss ▆▄▅█▅▂▄▄▁▆▇▄▅▄▄▃▁▅▅▃▅▄▆▄▇▂▁▃▆▄▄▂▇▂▂▆▆▆▄▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:               lr ████████▅▅▅▅▅▅▅▅▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:            score ▁▅▇██\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m006_fold0\u001b[0m: \u001b[34mhttps://wandb.ai/naoyakintoki/kaggle-g2net-gravitational-wave-detection/runs/3c8qpmu5\u001b[0m\n","========== CV ==========\n","Score: 0.8637\n"]}],"source":["# Training\n","!python train.py -i {COLAB_INPUT_DIR} --exp_num {exp_num} --wandb {WANDB_JSON_PATH}"]},{"cell_type":"markdown","metadata":{"id":"KRdT_uxMQR76"},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":540,"status":"ok","timestamp":1632145086644,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"-avA1lbZgEms","outputId":"48b64b67-238d-453a-ff48-4ee9c1157e40"},"outputs":[{"name":"stdout","output_type":"stream","text":["./output/tf_efficientnet_b7_ns_fold0_best_score.pth\n"]}],"source":["import glob\n","cps = glob.glob(f\"./output/*_best_score.pth\")\n","for c in cps:\n","    print(c)\n","cps = \",\".join(cps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331757,"status":"ok","timestamp":1632145423653,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"5PdFAVbIjiZx","outputId":"af840af4-9b3d-4fcf-bcd9-9eceefa51b9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating CQT kernels ...\r/usr/local/lib/python3.7/dist-packages/nnAudio/utils.py:326: SyntaxWarning: If fmax is given, n_bins will be ignored\n","  warnings.warn('If fmax is given, n_bins will be ignored',SyntaxWarning)\n","CQT kernels created, time used = 0.0092 seconds\n","2021-09-20 13:38:16.522777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:16.531614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:16.532277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:16.533181: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-09-20 13:38:16.533593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:16.534185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:16.534792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:17.018401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:17.019123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:17.019708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-20 13:38:17.020231: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-20 13:38:17.020272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14684 MB memory:  -\u003e device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","  0% 0/883 [00:00\u003c?, ?it/s]2021-09-20 13:38:20.819999: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","100% 883/883 [05:18\u003c00:00,  2.77it/s]\n"]}],"source":["# Make Submission\n","!python make_submission.py -c {cps}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7641,"status":"ok","timestamp":1632145431283,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"Lwb73ykXjiZz","outputId":"a862825d-aede-4787-b671-041cd780be59"},"outputs":[{"name":"stdout","output_type":"stream","text":["100% 4.67M/4.67M [00:06\u003c00:00, 812kB/s]\n","Successfully submitted to G2Net Gravitational Wave Detection"]}],"source":["# Post Submission\n","!kaggle competitions submit -c {COMPETITION_NAME} -f ./output/submission.csv -m {exp_num}"]},{"cell_type":"markdown","metadata":{"id":"51nl1PfEjU36"},"source":["## Save Latest Codes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1891,"status":"ok","timestamp":1632148096696,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"4OklWiADmdiT","outputId":"3d46365e-7578-4b28-fe7b-20b367ea745f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0000000000000000000000000000000000000000 d05673a445317df9b6c1c8c8854d572ff8bbf10b root \u003croot@0db5e98c3070.(none)\u003e 1632146750 +0000\tclone: from https://kn25ha01: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@github.com/kn25ha01/kaggle-g2net-gravitational-wave-detection.git\n"]}],"source":["!cat '/content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/005/.git/logs/refs/heads/main'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1632148473225,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"Kg1td1cxoTpq","outputId":"1010ae76-ea88-4307-bf84-27f5b5a04847"},"outputs":[{"name":"stdout","output_type":"stream","text":["0000000000000000000000000000000000000000 d05673a445317df9b6c1c8c8854d572ff8bbf10b root \u003croot@c99350affdc4.(none)\u003e 1632148438 +0000\tclone: from https://kn25ha01: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@github.com/kn25ha01/kaggle-g2net-gravitational-wave-detection.git\n"]}],"source":["!cat '/content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/005/.git/logs/refs/heads/main'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1632148496781,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"ZgLWOc_tnM2n","outputId":"4532fff4-847e-4b33-9f32-2906197bc452"},"outputs":[{"name":"stdout","output_type":"stream","text":["d05673a445317df9b6c1c8c8854d572ff8bbf10b\n"]}],"source":["!cat '/content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/005/.git/refs/heads/main'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"010K0uV2obPk"},"outputs":[],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1561,"status":"ok","timestamp":1632147767583,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"lZCC-_QMNc98","outputId":"494cd948-a6aa-4e4c-dc9c-c1b1a8bb77d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: cannot lock ref 'HEAD': Unable to create '/content/gdrive/MyDrive/kaggle/competitions/g2net-gravitational-wave-detection/working/005/.git/refs/heads/main\n","r.lock': Invalid argument\n","Everything up-to-date\n"]}],"source":["# Commit \u0026 Push\n","!git add .\n","!git commit -m \"update\"\n","!git push origin main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8528,"status":"ok","timestamp":1632148440384,"user":{"displayName":"かな","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02493058105386891928"},"user_tz":-540},"id":"NVHS3GD2fUPX","outputId":"98ce576b-367e-4a07-f9ab-192a648b2700"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove './.git': No such file or directory\n","/content/gdrive/MyDrive/kaggle/competitions/g2net-gravitational-wave-detection/working\n","Cloning into '999_'...\n","remote: Enumerating objects: 58, done.\u001b[K\n","remote: Counting objects: 100% (58/58), done.\u001b[K\n","remote: Compressing objects: 100% (40/40), done.\u001b[K\n","remote: Total 58 (delta 25), reused 41 (delta 14), pack-reused 0\u001b[K\n","Unpacking objects: 100% (58/58), done.\n","/content/gdrive/My Drive/kaggle/competitions/g2net-gravitational-wave-detection/working/005\n"]}],"source":["!rm -r ./.git\n","%cd ..\n","GIT_CONFIG_PATH = f'{KAGGLE_DIR}/secrets/github.json'\n","GIT_CONFIG = load_json(GIT_CONFIG_PATH)\n","GIT_USER_NAME = GIT_CONFIG['user.name']\n","GIT_USER_EMAIL = GIT_CONFIG['user.email']\n","GIT_TOKEN = GIT_CONFIG['token']\n","GIT_REPOSITORY_NAME = 'kaggle-' + COMPETITION_NAME\n","!git clone https://{GIT_USER_NAME}:{GIT_TOKEN}@github.com/{GIT_USER_NAME}/{GIT_REPOSITORY_NAME}.git 999_\n","!cp -r ./999_/.git ./005\n","!rm -r ./999_\n","%cd ./005\n","!git config --local user.name {GIT_USER_NAME}\n","!git config --local user.email {GIT_USER_EMAIL}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ol9EBt0DdaI_"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNqiGR8UBxOHbAnpInAjbgj","collapsed_sections":[],"machine_shape":"hm","name":"main.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}